#  Comprendre le fonctionnement d'un neurone

- Pour les dÃ©tails la roadmap est juste aprÃ¨s
- On va utiliser [julia](https://julialang.org/)
  - Manual: [Getting started](https://docs.julialang.org/en/v1/manual/getting-started/)
- Il existe un notebook natif pour Julia:
  - Executer le notebook [Pluto](https://plutojl.org/):
```Julia
using Pluto
Pluto.run()
```
  - mais on peut aussi utilise Jupyter, il faut installer le package `IJulia`. Le Markdown dans jupyter accepte LaTeX ce qui permet d'utiliser une syntax mathÃ©matique.
```sh
# jupyter lab --no-browser
```
- Status:
  - [x] Ã‰tape 0 â€” Vision globale
  - [x] ğŸ§® Ã‰tape 1 â€” Comprendre la dÃ©rivÃ©e comme "sensibilitÃ©"
  - [x] ğŸ“‰ Ã‰tape 2 â€” Minimisation dâ€™une fonction (descente de gradient 1D)
  - [x] ğŸŒ„ Ã‰tape 3 â€” Gradient en dimension 2+
  - [x] ğŸ”— Ã‰tape 4 â€” RÃ¨gle de la chaÃ®ne (LE cÅ“ur du deep learning)
  - [x] âš™ï¸ Ã‰tape 5 â€” Construire un neurone Ã  la main
  - [ ] ğŸ” Ã‰tape 6 â€” Backpropagation (sans lâ€™appeler comme Ã§a)
  - [ ] ğŸ§± Ã‰tape 7 â€” Plusieurs entrÃ©es

---

# ğŸ§  Roadmap : des dÃ©rivÃ©es â†’ gradients â†’ neurone rÃ©el

Objectif final : comprendre profondÃ©ment ce qui se passe dans un neurone (type perceptron / MLP), mathÃ©matiquement
et intuitivement.

## Ã‰tape 0 â€” Vision globale

Un neurone =

```
entrÃ©e â†’ somme pondÃ©rÃ©e â†’ fonction dâ€™activation â†’ sortie
```

MathÃ©matiquement :

```
y = Ïƒ(wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b)
```

Lâ€™apprentissage consiste Ã  ajuster les poids `w` pour minimiser une erreur.

Et tout repose sur :
â†’ dÃ©rivÃ©es
â†’ gradients
â†’ descente de gradient

## ğŸ§® Ã‰tape 1 â€” Comprendre la dÃ©rivÃ©e comme "sensibilitÃ©"

### Objectif

Comprendre :

> "Si je change un paramÃ¨tre un tout petit peu, quâ€™est-ce que Ã§a change au rÃ©sultat ?"

Dans Pluto :

* tracer une fonction simple
* afficher sa dÃ©rivÃ©e
* voir lâ€™effet local

Exemples Ã  explorer :

```
f(x) = xÂ²
f(x) = sin(x)
f(x) = e^x
```

ExpÃ©riences :

* zoomer autour dâ€™un point
* visualiser la pente
* approximer numÃ©riquement :

```
f'(x) â‰ˆ (f(x+h) - f(x)) / h
```

Intuition clÃ© :

> Une dÃ©rivÃ©e mesure une influence.

## ğŸ“‰ Ã‰tape 2 â€” Minimisation dâ€™une fonction (descente de gradient 1D)

### Objectif

Comprendre comment on "apprend" sans neurone.

ProblÃ¨me :

```
minimiser f(x) = (x-3)^2
```

Algorithme :

```
x = x - Î· * f'(x)
```

Explorer :

* diffÃ©rents learning rates
* convergence
* divergence

Pluto est parfait pour :

* slider sur Î·
* voir la trajectoire

Concept clÃ© :

> Apprendre = descendre une pente.

## ğŸŒ„ Ã‰tape 3 â€” Gradient en dimension 2+

Passer Ã  :

```
f(x, y) = xÂ² + yÂ²
```

Comprendre :

* gradient = direction de plus forte montÃ©e
* descente = direction opposÃ©e

ExpÃ©riences :

* champ de vecteurs
* trajectoire dâ€™optimisation

Intuition clÃ© :

> Le gradient indique "oÃ¹ corriger".

## ğŸ”— Ã‰tape 4 â€” RÃ¨gle de la chaÃ®ne (LE cÅ“ur du deep learning)

Câ€™est le moment le plus important.

Comprendre :

```
f(x) = sin(xÂ²)
```

DÃ©rivÃ©e :

```
f'(x) = cos(xÂ²) * 2x
```

Puis gÃ©nÃ©raliser :

```
z = f(g(x))
```

La dÃ©rivÃ©e se propage.

Concept clÃ© :

> Lâ€™erreur peut remonter dans un systÃ¨me composÃ©.

Câ€™est exactement :
**backpropagation**

## âš™ï¸ Ã‰tape 5 â€” Construire un neurone Ã  la main

CrÃ©er un neurone simple :

```
y = Ïƒ(wx + b)
```

Choisir :

* Ïƒ = sigmoid
* ou tanh
* ou ReLU

Puis dÃ©finir une erreur :

```
L = (y - target)^2
```

Et calculer :

```
dL/dw
dL/db
```

## ğŸ” Ã‰tape 6 â€” Backpropagation (sans lâ€™appeler comme Ã§a)

Faire un mini systÃ¨me :

```
x â†’ neurone â†’ erreur
```

Puis :

* calculer dÃ©rivÃ©es Ã  la main
* ajuster w
* observer lâ€™apprentissage

Câ€™est LE moment "aha".

## ğŸ§± Ã‰tape 7 â€” Plusieurs entrÃ©es

Passer Ã  :

```
y = Ïƒ(w1x1 + w2x2 + b)
```

Visualiser :

* plan de dÃ©cision
* frontiÃ¨re linÃ©aire

Comprendre :

> Un neurone = sÃ©parateur linÃ©aire.

## ğŸŒ Ã‰tape 8 â€” Plusieurs neurones (MLP)

Construire :

```
2 entrÃ©es â†’ 3 neurones â†’ 1 sortie
```

Et voir apparaÃ®tre :

* non-linÃ©aritÃ©
* formes complexes
* XOR

Moment clÃ© :

> Un seul neurone est limitÃ©.
> Plusieurs = intelligence Ã©mergente.

## ğŸ§ª Ã‰tape 9 â€” Pluto vs Clojure (comment mixer)

### Pluto â†’ idÃ©al pour :

* visualisation
* intuition
* maths
* sliders
* exploration

### Clojure â†’ idÃ©al pour :

* live coding
* systÃ¨mes dynamiques
* exploration structurelle
* manipulations fonctionnelles

# ğŸ§© Suggestion dâ€™architecture hybride

## Julia/Pluto

* explorer maths
* tracer gradients
* visualiser optimisation

## Clojure

* implÃ©menter neurones
* expÃ©rimenter architectures
* jouer avec propagation

# ğŸ§­ Ordre conseillÃ© (trÃ¨s important)

1. dÃ©rivÃ©es 1D
2. gradient descent 1D
3. gradients 2D
4. rÃ¨gle de la chaÃ®ne
5. 1 neurone
6. apprentissage du neurone
7. multi-neurones

# ğŸ’¡ Projet fil rouge (excellent pour apprendre)

CrÃ©er un neurone qui apprend Ã  approximer :

```
y = xÂ²
```

Puis :

```
y = sin(x)
```

Puis :

```
classifier des points 2D
```

---

Parfait. On va faire la chaÃ®ne complÃ¨te, trÃ¨s lentement, et en gardant exactement ton intuition sur
â€œles autres variables sont des constantesâ€.

On part dâ€™un neurone simple.

---

## 1ï¸âƒ£ Le neurone comme composition de fonctions

On a 3 Ã©tapes :

1. Somme pondÃ©rÃ©e
   [
   z = w_1 x_1 + w_2 x_2 + b
   ]

2. Activation
   [
   y = \sigma(z)
   ]

3. Erreur
   [
   E = \frac12 (y - y_{\text{vrai}})^2
   ]

Donc en rÃ©alitÃ© :

[
w_i \rightarrow z \rightarrow y \rightarrow E
]

Câ€™est une fonction composÃ©e.

---

## 2ï¸âƒ£ On veut quoi exactement ?

On veut savoir :

[
\frac{\partial E}{\partial w_i}
]

Câ€™est-Ã -dire :

> Si je change lÃ©gÃ¨rement le poids (w_i), comment lâ€™erreur change ?

---

## 3ï¸âƒ£ La chaÃ®ne complÃ¨te (version simple)

La rÃ¨gle de la chaÃ®ne donne :

[
\frac{\partial E}{\partial w_i}
===============================

\frac{\partial E}{\partial y}
\cdot
\frac{\partial y}{\partial z}
\cdot
\frac{\partial z}{\partial w_i}
]

Câ€™est exactement comme :

[
h(x) = f(g(u(x)))
\Rightarrow
h'(x) = f'(g(u)) \cdot g'(u) \cdot u'(x)
]

---

## 4ï¸âƒ£ Calcul des 3 morceaux (un par un)

### a) DÃ©rivÃ©e de lâ€™erreur par rapport Ã  y

[
E = \frac12 (y - y_{\text{vrai}})^2
]

Donc :

[
\frac{\partial E}{\partial y} = (y - y_{\text{vrai}})
]

Intuition :
si y est trop grand â†’ erreur positive
si y est trop petit â†’ erreur nÃ©gative

---

### b) DÃ©rivÃ©e de y par rapport Ã  z

[
y = \sigma(z)
]

Pour la sigmoid :

[
\frac{\partial y}{\partial z} = \sigma(z)(1 - \sigma(z))
]

Donc :

[
\frac{\partial y}{\partial z} = y(1-y)
]

---

### c) DÃ©rivÃ©e de z par rapport Ã  w_i

[
z = w_1 x_1 + w_2 x_2 + b
]

On dÃ©rive par rapport Ã  (w_i).

Tous les autres termes sont constants.

Il reste juste :

[
\frac{\partial z}{\partial w_i} = x_i
]

Câ€™est exactement ce que tu as compris avec :

> f(x,y) = x + y â†’ dÃ©rivÃ©e par rapport Ã  x = 1 car y est constant.

---

## 5ï¸âƒ£ On assemble tout

[
\frac{\partial E}{\partial w_i}
===============================

(y - y_{\text{vrai}})
\cdot
y(1-y)
\cdot
x_i
]

Câ€™est LE rÃ©sultat central.

---

## 6ï¸âƒ£ InterprÃ©tation trÃ¨s intuitive

Chaque facteur a un sens :

* (y - y_{\text{vrai}})
  â†’ Ã  quel point on se trompe

* (y(1-y))
  â†’ Ã  quel point le neurone rÃ©agit au changement de z

* (x_i)
  â†’ Ã  quel point ce poids participe au rÃ©sultat

Donc :

> Si (x_i = 0) â†’ ce poids ne joue aucun rÃ´le â†’ gradient = 0

Câ€™est trÃ¨s logique.

---

## 7ï¸âƒ£ Et lÃ  tu vois le lien profond avec la rÃ¨gle de la chaÃ®ne

On a littÃ©ralement :

[
w_i \rightarrow z \rightarrow y \rightarrow E
]

Et on â€œremonteâ€ :

* erreur â†’ sortie â†’ somme â†’ poids

Câ€™est exactement Ã§a la **backpropagation**.

---

## 8ï¸âƒ£ Image mentale importante (la plus juste)

Pense Ã  une chaÃ®ne :

```
w_i â”€â”€â–º z â”€â”€â–º y â”€â”€â–º E
```

La dÃ©rivÃ©e remonte :

```
âˆ‚E/âˆ‚w_i =
(âˆ‚E/âˆ‚y)
Ã— (âˆ‚y/âˆ‚z)
Ã— (âˆ‚z/âˆ‚w_i)
```

Câ€™est juste :

> la rÃ¨gle de la chaÃ®ne appliquÃ©e Ã  un systÃ¨me en cascade.

---

## 9ï¸âƒ£ Le moment clÃ© Ã  retenir

Tu as dÃ©bloquÃ© le point le plus difficile :

> Quand on dÃ©rive par rapport Ã  w_i, tous les autres w_j sont des constantes.

Câ€™est exactement Ã§a qui rend le calcul possible.

Et câ€™est Ã§a qui permet :

* un gradient pour w1
* un gradient pour w2
* un gradient pour chaque poids

IndÃ©pendamment.

---

## 10ï¸âƒ£ Question pour vÃ©rifier un dÃ©clic profond

Est-ce que cette phrase te paraÃ®t maintenant claire :

> â€œBackpropagation, câ€™est juste la rÃ¨gle de la chaÃ®ne appliquÃ©e Ã  une longue composition de fonctions.â€

Ou tu sens encore un petit flou quelque part ?

