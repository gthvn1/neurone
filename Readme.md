#  Comprendre le fonctionnement d'un neurone

- Pour les dÃ©tails la roadmap est juste aprÃ¨s
- On va utiliser [julia](https://julialang.org/)
  - Manual: [Getting started](https://docs.julialang.org/en/v1/manual/getting-started/)
- Il existe un notebook natif pour Julia:
  - Executer le notebook [Pluto](https://plutojl.org/):
```Julia
using Pluto
Pluto.run()
```
  - mais on peut aussi utilise Jupyter, il faut installer le package `IJulia`. Le Markdown dans jupyter accepte LaTeX ce qui permet d'utiliser une syntax mathÃ©matique.
```sh
# jupyter lab --no-browser
```
- Status:
  - [x] Ã‰tape 0 â€” Vision globale
  - [x] ðŸ§® Ã‰tape 1 â€” Comprendre la dÃ©rivÃ©e comme "sensibilitÃ©"
  - [x] ðŸ“‰ Ã‰tape 2 â€” Minimisation dâ€™une fonction (descente de gradient 1D)
  - [x] ðŸŒ„ Ã‰tape 3 â€” Gradient en dimension 2+
  - [x] ðŸ”— Ã‰tape 4 â€” RÃ¨gle de la chaÃ®ne (LE cÅ“ur du deep learning)
  - [x] âš™ï¸ Ã‰tape 5 â€” Construire un neurone Ã  la main
  - [x] ðŸ” Ã‰tape 6 â€” Backpropagation (sans lâ€™appeler comme Ã§a)
  - [ ] ðŸ§± Ã‰tape 7 â€” Plusieurs entrÃ©es

---

# ðŸ§  Roadmap : des dÃ©rivÃ©es â†’ gradients â†’ neurone rÃ©el

Objectif final : comprendre profondÃ©ment ce qui se passe dans un neurone (type perceptron / MLP), mathÃ©matiquement
et intuitivement.

## Ã‰tape 0 â€” Vision globale

Un neurone =

```
entrÃ©e â†’ somme pondÃ©rÃ©e â†’ fonction dâ€™activation â†’ sortie
```

MathÃ©matiquement :

```
y = Ïƒ(wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b)
```

Lâ€™apprentissage consiste Ã  ajuster les poids `w` pour minimiser une erreur.

Et tout repose sur :
â†’ dÃ©rivÃ©es
â†’ gradients
â†’ descente de gradient

## ðŸ§® Ã‰tape 1 â€” Comprendre la dÃ©rivÃ©e comme "sensibilitÃ©"

### Objectif

Comprendre :

> "Si je change un paramÃ¨tre un tout petit peu, quâ€™est-ce que Ã§a change au rÃ©sultat ?"

Dans Pluto :

* tracer une fonction simple
* afficher sa dÃ©rivÃ©e
* voir lâ€™effet local

Exemples Ã  explorer :

```
f(x) = xÂ²
f(x) = sin(x)
f(x) = e^x
```

ExpÃ©riences :

* zoomer autour dâ€™un point
* visualiser la pente
* approximer numÃ©riquement :

```
f'(x) â‰ˆ (f(x+h) - f(x)) / h
```

Intuition clÃ© :

> Une dÃ©rivÃ©e mesure une influence.

## ðŸ“‰ Ã‰tape 2 â€” Minimisation dâ€™une fonction (descente de gradient 1D)

### Objectif

Comprendre comment on "apprend" sans neurone.

ProblÃ¨me :

```
minimiser f(x) = (x-3)^2
```

Algorithme :

```
x = x - Î· * f'(x)
```

Explorer :

* diffÃ©rents learning rates
* convergence
* divergence

Pluto est parfait pour :

* slider sur Î·
* voir la trajectoire

Concept clÃ© :

> Apprendre = descendre une pente.

## ðŸŒ„ Ã‰tape 3 â€” Gradient en dimension 2+

Passer Ã  :

```
f(x, y) = xÂ² + yÂ²
```

Comprendre :

* gradient = direction de plus forte montÃ©e
* descente = direction opposÃ©e

ExpÃ©riences :

* champ de vecteurs
* trajectoire dâ€™optimisation

Intuition clÃ© :

> Le gradient indique "oÃ¹ corriger".

## ðŸ”— Ã‰tape 4 â€” RÃ¨gle de la chaÃ®ne (LE cÅ“ur du deep learning)

Câ€™est le moment le plus important.

Comprendre :

```
f(x) = sin(xÂ²)
```

DÃ©rivÃ©e :

```
f'(x) = cos(xÂ²) * 2x
```

Puis gÃ©nÃ©raliser :

```
z = f(g(x))
```

La dÃ©rivÃ©e se propage.

Concept clÃ© :

> Lâ€™erreur peut remonter dans un systÃ¨me composÃ©.

Câ€™est exactement :
**backpropagation**

## âš™ï¸ Ã‰tape 5 â€” Construire un neurone Ã  la main

CrÃ©er un neurone simple :

```
y = Ïƒ(wx + b)
```

Choisir :

* Ïƒ = sigmoid
* ou tanh
* ou ReLU

Puis dÃ©finir une erreur :

```
L = (y - target)^2
```

Et calculer :

```
dL/dw
dL/db
```

## ðŸ” Ã‰tape 6 â€” Backpropagation (sans lâ€™appeler comme Ã§a)

Faire un mini systÃ¨me :

```
x â†’ neurone â†’ erreur
```

Puis :

* calculer dÃ©rivÃ©es Ã  la main
* ajuster w
* observer lâ€™apprentissage

Câ€™est LE moment "aha".

## ðŸ§± Ã‰tape 7 â€” Plusieurs entrÃ©es

Passer Ã  :

```
y = Ïƒ(w1x1 + w2x2 + b)
```

Visualiser :

* plan de dÃ©cision
* frontiÃ¨re linÃ©aire

Comprendre :

> Un neurone = sÃ©parateur linÃ©aire.

## ðŸŒ Ã‰tape 8 â€” Plusieurs neurones (MLP)

Construire :

```
2 entrÃ©es â†’ 3 neurones â†’ 1 sortie
```

Et voir apparaÃ®tre :

* non-linÃ©aritÃ©
* formes complexes
* XOR

Moment clÃ© :

> Un seul neurone est limitÃ©.
> Plusieurs = intelligence Ã©mergente.

les autres w_j sont des constantes.

Câ€™est exactement Ã§a qui rend le calcul possible.

Et câ€™est Ã§a qui permet :

* un gradient pour w1
* un gradient pour w2
* un gradient pour chaque poids

IndÃ©pendamment.

---
