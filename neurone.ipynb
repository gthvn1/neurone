{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5858e52a-18a0-466e-bfac-f28626b0b087",
   "metadata": {},
   "source": [
    "# Description d'un neurone\n",
    "\n",
    "Un neurone est une fonction pondérée de la forme :  \n",
    "\n",
    "$$\n",
    "z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + b\n",
    "$$\n",
    "\n",
    "où $w_n$ est un poids et $b$ un biais.  \n",
    "Un neurone peut avoir plusieurs entrées. Ici, nous en avons deux.\n",
    "\n",
    "L'objectif est d'ajuster les poids ainsi que le biais afin d'obtenir la sortie attendue.  \n",
    "Notons $t$ (*target*) la sortie attendue et $y$ la valeur calculée par le neurone.\n",
    "\n",
    "La valeur calculée n'est pas directement la sortie de l'équation décrite au début : elle est le résultat d'une fonction d’activation.  \n",
    "Nous allons utiliser une fonction d’activation classique : la **sigmoïde**, notée $\\sigma(x)$.\n",
    "\n",
    "Nous avons donc :\n",
    "\n",
    "$$\n",
    "y = \\sigma(z) = \\frac{1}{1 + \\exp(-z)}\n",
    "$$\n",
    "\n",
    "> **Note :**  \n",
    "> La fonction sigmoïde (notée $\\sigma$) est très utilisée en classification binaire.\n",
    "> - Elle transforme toute valeur réelle en une valeur comprise entre **0 et 1**.\n",
    "> - Elle est **continue et dérivable** partout.\n",
    "> - Sa dérivée s’écrit :\n",
    ">   $$\n",
    ">   \\sigma'(z) = \\sigma(z)(1 - \\sigma(z))\n",
    ">   $$\n",
    "> - Comme la sortie est comprise entre 0 et 1, on peut interpréter la sortie d’un neurone sigmoïde comme une **probabilité** d’appartenir à la classe 1.\n",
    "\n",
    "Afin de comparer la valeur calculée par le neurone à la valeur attendue, nous utilisons une fonction d’erreur :\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2} (y - t)^2\n",
    "$$\n",
    "\n",
    "Il s’agit d’une fonction quadratique. L’objectif est de minimiser cette erreur.  \n",
    "Nous pouvons le faire grâce à la **descente de gradient**.\n",
    "\n",
    "> **Note :**  \n",
    "> En pratique, on préfère souvent utiliser la combinaison *sigmoïde + entropie croisée*,  \n",
    "> mais pour cette première approche, nous utilisons l’erreur quadratique afin de simplifier les calculs.\n",
    "\n",
    "## Calcul des dérivées\n",
    "\n",
    "Pour appliquer la descente de gradient, nous utilisons la règle de la chaîne.  \n",
    "Nous cherchons à minimiser l’erreur par rapport à $w_1$, $w_2$ et $b$.\n",
    "\n",
    "Nous calculons donc :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_1}\n",
    "=\n",
    "\\frac{\\partial E}{\\partial y}\n",
    "\\cdot\n",
    "\\frac{\\partial y}{\\partial z}\n",
    "\\cdot\n",
    "\\frac{\\partial z}{\\partial w_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_2}\n",
    "=\n",
    "\\frac{\\partial E}{\\partial y}\n",
    "\\cdot\n",
    "\\frac{\\partial y}{\\partial z}\n",
    "\\cdot\n",
    "\\frac{\\partial z}{\\partial w_2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial b}\n",
    "=\n",
    "\\frac{\\partial E}{\\partial y}\n",
    "\\cdot\n",
    "\\frac{\\partial y}{\\partial z}\n",
    "\\cdot\n",
    "\\frac{\\partial z}{\\partial b}\n",
    "$$\n",
    "\n",
    "Avec :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial y} = y - t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial z} = y (1 - y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial w_1} = x_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial w_2} = x_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial b} = 1\n",
    "$$\n",
    "\n",
    "## Expression finale des gradients\n",
    "\n",
    "Nous obtenons finalement :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_1}\n",
    "=\n",
    "(y - t) \\cdot y \\cdot (1 - y) \\cdot x_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_2}\n",
    "=\n",
    "(y - t) \\cdot y \\cdot (1 - y) \\cdot x_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial b}\n",
    "=\n",
    "(y - t) \\cdot y \\cdot (1 - y)\n",
    "$$\n",
    "\n",
    "## Mise à jour des paramètres\n",
    "\n",
    "Une fois les dérivées calculées pour chaque poids et pour le biais, nous pouvons ajuster les paramètres du neurone et réitérer l’opération jusqu’à obtenir une réponse correcte.  \n",
    "Le neurone aura alors terminé son apprentissage.\n",
    "\n",
    "La mise à jour des paramètres s’effectue selon la règle :\n",
    "\n",
    "$$\n",
    "w_{\\text{next}} = w_{\\text{current}} - \\eta \\cdot \\frac{\\partial E}{\\partial w_{\\text{current}}}\n",
    "$$\n",
    "\n",
    "où $\\eta$ est le **taux d’apprentissage** (*learning rate*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907413b5-c320-4625-8e3d-336ccab85193",
   "metadata": {},
   "source": [
    "# Neurone — fiche synthèse\n",
    "\n",
    "## Modèle\n",
    "\n",
    "On considère un neurone à deux entrées :\n",
    "\n",
    "- $z = w_1 x_1 + w_2 x_2 + b$\n",
    "- $y = \\sigma(z)$\n",
    "- $E = \\frac{1}{2}(y - t)^2$\n",
    "\n",
    "avec :\n",
    "- $w_1, w_2$ : poids  \n",
    "- $b$ : biais  \n",
    "- $t$ : cible (*target*)  \n",
    "- $y$ : sortie du neurone  \n",
    "\n",
    "---\n",
    "\n",
    "## Sigmoïde\n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "Propriétés utiles :\n",
    "\n",
    "- sortie dans $[0,1]$\n",
    "- interprétable comme une probabilité\n",
    "- dérivée simple :  \n",
    "  $\\sigma'(z) = \\sigma(z)(1-\\sigma(z))$\n",
    "\n",
    "Donc :\n",
    "\n",
    "- $\\frac{\\partial y}{\\partial z} = y(1-y)$\n",
    "\n",
    "---\n",
    "\n",
    "## Descente de gradient\n",
    "\n",
    "Objectif : minimiser $E$ par rapport à $w_1$, $w_2$ et $b$.\n",
    "\n",
    "Règle de la chaîne :\n",
    "\n",
    "$\\frac{\\partial E}{\\partial w} =\n",
    "\\frac{\\partial E}{\\partial y}\n",
    "\\frac{\\partial y}{\\partial z}\n",
    "\\frac{\\partial z}{\\partial w}$\n",
    "\n",
    "Dérivées intermédiaires :\n",
    "\n",
    "- $\\frac{\\partial E}{\\partial y} = y - t$\n",
    "- $\\frac{\\partial y}{\\partial z} = y(1-y)$\n",
    "- $\\frac{\\partial z}{\\partial w_1} = x_1$\n",
    "- $\\frac{\\partial z}{\\partial w_2} = x_2$\n",
    "- $\\frac{\\partial z}{\\partial b} = 1$\n",
    "\n",
    "---\n",
    "\n",
    "## Gradients finaux\n",
    "\n",
    "| Paramètre | Gradient |\n",
    "|-----------|----------|\n",
    "| $w_1$ | $(y - t)\\, y(1-y)\\, x_1$ |\n",
    "| $w_2$ | $(y - t)\\, y(1-y)\\, x_2$ |\n",
    "| $b$   | $(y - t)\\, y(1-y)$ |\n",
    "\n",
    "---\n",
    "\n",
    "## Mise à jour\n",
    "\n",
    "$w \\leftarrow w - \\eta \\, \\frac{\\partial E}{\\partial w}$\n",
    "\n",
    "où $\\eta$ est le taux d’apprentissage.\n",
    "\n",
    "---\n",
    "\n",
    "### Note personnelle\n",
    "\n",
    "En pratique :  \n",
    "on préfère **sigmoïde + entropie croisée**, car le gradient se simplifie en :\n",
    "\n",
    "$\\frac{\\partial E}{\\partial z} = y - t$\n",
    "\n",
    "Mais ici on garde l’erreur quadratique pour la pédagogie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af71c40-b547-4f57-b77f-d31c3ac0fc31",
   "metadata": {},
   "source": [
    "# Exemple pratique, un ET logique\n",
    "\n",
    "- Notre neurone va devoir repondre a la question:\n",
    "\n",
    "| x0 | x1 | t |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 0 |\n",
    "| 0  | 1  | 0 |\n",
    "| 1  | 0  | 0 |\n",
    "| 1  | 1  | 1 |\n",
    "\n",
    "- Nous allons prendre comme valeur de départ:\n",
    "  - $w_0 = 0.5$\n",
    "  - $w_1 = 0.5$\n",
    "  - $b  = - 0.5$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cf686c3-2381-40ad-9602-9fbedc04baee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeurs initiales\n",
    "n = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3810f99-6ac2-49a0-af80-e7cba16793b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(z)\n",
    "    1 / (1 + exp(-z)) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c86b5765-6f41-4b86-ab56-10f5455ec681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one_step (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le but de cette fonction est de calculer les prochaines valeurs des poids et du biais\n",
    "function one_step(w0, w1, b, x0, x1, t, n)\n",
    "    z = w0 * x0 + w1 * x1 + b\n",
    "    y = sigmoid(z)\n",
    "\n",
    "    δ = (y - t) * y * (1 - y)\n",
    "    \n",
    "    w0 - n * δ * x0, w1 - n * δ * x1, b - n * δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ea65d10-824e-4a1d-bf6c-b897342b1f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5, -0.5000088723458674)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Premier pas en prenant la premiere ligne du AND\n",
    "w0, w1, b = one_step(0.5, 0.5, -0.5, 0, 0, 0, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce6c75b3-67e9-47b8-b611-6701c37da10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.4999875000554524, -0.500021372290415)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second pas en prenant la seconde ligne\n",
    "w0, w1, b = one_step(w0, w1, b, 0, 1, 0, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83f6c65a-c179-4c78-8244-153668f638b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49998750013357823, 0.4999875000554524, -0.5000338721568367)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Troisieme pas en prenant la troisieme \n",
    "w0, w1, b = one_step(w0, w1, b, 1, 0, 0, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2779d6de-5c04-4227-ac4d-8026bc215fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4999963729325061, 0.49999637285438026, -0.5000249993579088)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Et enfin dernier pas de la premiere iteration avec la derniere ligne\n",
    "w0, w1, b = one_step(w0, w1, b, 1, 1, 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89483711-b1de-4cad-a459-e381330a4f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one_iteration (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    (0, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (1, 0, 0),\n",
    "    (1, 1, 1)]\n",
    "\n",
    "function one_iteration(w0, w1, b, data, n)\n",
    "    println(\"n = \", n)\n",
    "    for (x0, x1, t) in data\n",
    "        println(\"avant: \", w0, \" \", w1, \" \", b)\n",
    "        w0, w1, b = one_step(w0, w1, b, x0, x1, t, n)\n",
    "        println(\"apres: \", w0, \" \", w1, \" \", b)\n",
    "    end\n",
    "\n",
    "    return w0, w1, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d8b3f07-f4e5-49ff-9619-aac6f29d30bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 0.0001\n",
      "avant: 0.5 0.5 -0.5\n",
      "apres: 0.5 0.5 -0.5000088723458674\n",
      "avant: 0.5 0.5 -0.5000088723458674\n",
      "apres: 0.5 0.4999875000554524 -0.500021372290415\n",
      "avant: 0.5 0.4999875000554524 -0.500021372290415\n",
      "apres: 0.49998750013357823 0.4999875000554524 -0.5000338721568367\n",
      "avant: 0.49998750013357823 0.4999875000554524 -0.5000338721568367\n",
      "apres: 0.4999963729325061 0.49999637285438026 -0.5000249993579088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4999963729325061, 0.49999637285438026, -0.5000249993579088)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_iteration(0.5, 0.5, -0.5, data, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a78d22-530d-44e5-b55f-2a5a49416d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
